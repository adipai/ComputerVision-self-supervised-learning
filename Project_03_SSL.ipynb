{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adipai/cv-ssl/blob/main/Project_03_SSL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mmengine==0.10.3"
      ],
      "metadata": {
        "id": "MdmJbUDHI0xH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TEWLbzUG5-K"
      },
      "source": [
        "# ECE763 Project 03 (Final Course Project): Self-Supervised Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5knZZItG5-L"
      },
      "source": [
        "### Objectives\n",
        "\n",
        "* Implemenet two self-supervised contrastive learning methods\n",
        "* Compare the representaitons via SSL with supervised baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhIZODk2G5-L"
      },
      "source": [
        "### How to submit your solutions\n",
        "\n",
        "* Add your NCSU IDs (all team members if had) as the postfix of the notebook filename.\n",
        "* `If you have a team, please clearly state who contribute to which part(s) of the project.`\n",
        "* Submit two versions of your notebook, one is fully executed with all outputs (`Project_03_ViT_twu19_results.ipynb`), and the other with all outputs cleared (`Project_03_ViT_twu19_empty.ipynb`). We will re-run the latter and expect the results will be exactly the same as those in the former.\n",
        "* No late days"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icdEyCj7G5-L"
      },
      "source": [
        "### Team Contributions (if applicable)\n",
        "\n",
        "* Rishi Singhal\n",
        "* Nitin Joseph\n",
        "* Aditya Pai Brahmavar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a29hlTEoG5-L"
      },
      "source": [
        "### Overview\n",
        "\n",
        "How to learn good representations from unlabeled data (e.g., imagery data)? First of all, this data still contains a lot of information from which we can learn: how are the images different from each other? What patterns are descriptive for certain images? Can we cluster the images? And so on. Methods for self-supervised learning try to learn as much as possible from the data alone, so it can quickly be finetuned for a specific classification task.\n",
        "\n",
        "The benefit of self-supervised learning is that a large dataset can often easily be obtained. For instance, if we want to train a vision model on semantic segmentation for autonomous driving, we can collect large amounts of data by simply installing a camera in a car, and driving through a city for an hour. In contrast, if we would want to do supervised learning, we would have to manually label all those images before training a model. This is extremely expensive, and would likely take a couple of months to manually label the same amount of data. Further, self-supervised learning can provide an alternative to transfer learning from models pretrained on ImageNet since we could pretrain a model on a specific dataset/situation, e.g. traffic scenarios for autonomous driving.\n",
        "\n",
        "Within the last several years, a lot of new approaches have been proposed for self-supervised learning using images, that have resulted in great improvements over supervised models when few labels are available.\n",
        "\n",
        "Check our lecture notes 18-19 and references therein.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gxu6pL7_G5-M"
      },
      "source": [
        "## Let's first start with importing our standard libraries below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_PvPmm4KG5-M"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "## Standard libraries\n",
        "import os\n",
        "from copy import deepcopy\n",
        "import json\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import copy\n",
        "import time\n",
        "\n",
        "## Imports for plotting\n",
        "%matplotlib inline\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm\n",
        "import seaborn as sns\n",
        "sns.set_theme()\n",
        "\n",
        "## Progress bar\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "## typing\n",
        "from typing import (\n",
        "    Any,\n",
        "    Callable,\n",
        "    Dict,\n",
        "    List,\n",
        "    Optional,\n",
        "    Sequence,\n",
        "    Set,\n",
        "    Tuple,\n",
        "    Type,\n",
        "    Union,\n",
        ")\n",
        "\n",
        "try:\n",
        "    from typing import Literal\n",
        "except ImportError:\n",
        "    from typing_extensions import Literal\n",
        "\n",
        "## PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data\n",
        "import torch.optim as optim\n",
        "\n",
        "## PyTorch Torchvision\n",
        "import torchvision\n",
        "from torchvision.datasets import CIFAR10,STL10\n",
        "from torchvision import transforms\n",
        "\n",
        "\n",
        "# PyTorch Lightning\n",
        "try:\n",
        "    import pytorch_lightning as pl\n",
        "except ModuleNotFoundError:\n",
        "    !pip install --quiet pytorch-lightning>=1.6\n",
        "    import pytorch_lightning as pl\n",
        "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n",
        "\n",
        "# Import tensorboard\n",
        "%load_ext tensorboard\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAPuvpTZG5-M"
      },
      "source": [
        "## Identify the system"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zM_iL9ciG5-N",
        "outputId": "dfb1f1a2-0d24-4485-86b2-41dc533f8331"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================== System Information ========================================\n",
            "System: Linux\n",
            "Node Name: 9634aced87e1\n",
            "Release: 6.1.58+\n",
            "Version: #1 SMP PREEMPT_DYNAMIC Sat Nov 18 15:31:17 UTC 2023\n",
            "Machine: x86_64\n",
            "Processor: x86_64\n",
            "======================================== Environment Information ========================================\n",
            "OrderedDict([('sys.platform', 'linux'),\n",
            "             ('Python', '3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]'),\n",
            "             ('CUDA available', True),\n",
            "             ('MUSA available', False),\n",
            "             ('numpy_random_seed', 2147483648),\n",
            "             ('GPU 0', 'Tesla T4'),\n",
            "             ('CUDA_HOME', '/usr/local/cuda'),\n",
            "             ('NVCC', 'Cuda compilation tools, release 12.2, V12.2.140'),\n",
            "             ('GCC',\n",
            "              'x86_64-linux-gnu-gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0'),\n",
            "             ('PyTorch', '2.2.1+cu121'),\n",
            "             ('PyTorch compiling details',\n",
            "              'PyTorch built with:\\n'\n",
            "              '  - GCC 9.3\\n'\n",
            "              '  - C++ Version: 201703\\n'\n",
            "              '  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product '\n",
            "              'Build 20220804 for Intel(R) 64 architecture applications\\n'\n",
            "              '  - Intel(R) MKL-DNN v3.3.2 (Git Hash '\n",
            "              '2dc95a2ad0841e29db8b22fbccaf3e5da7992b01)\\n'\n",
            "              '  - OpenMP 201511 (a.k.a. OpenMP 4.5)\\n'\n",
            "              '  - LAPACK is enabled (usually provided by MKL)\\n'\n",
            "              '  - NNPACK is enabled\\n'\n",
            "              '  - CPU capability usage: AVX512\\n'\n",
            "              '  - CUDA Runtime 12.2\\n'\n",
            "              '  - Built with CUDA Runtime 12.1\\n'\n",
            "              '  - NVCC architecture flags: '\n",
            "              '-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\\n'\n",
            "              '  - CuDNN 8.9.6  (built against CUDA 12.2)\\n'\n",
            "              '    - Built with CuDNN 8.9.2\\n'\n",
            "              '  - Magma 2.6.1\\n'\n",
            "              '  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, '\n",
            "              'CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, '\n",
            "              'CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= '\n",
            "              '-D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 '\n",
            "              '-fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG '\n",
            "              '-DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK '\n",
            "              '-DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK '\n",
            "              '-DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra '\n",
            "              '-Werror=return-type -Werror=non-virtual-dtor '\n",
            "              '-Werror=bool-operation -Wnarrowing '\n",
            "              '-Wno-missing-field-initializers -Wno-type-limits '\n",
            "              '-Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter '\n",
            "              '-Wno-unused-function -Wno-unused-result -Wno-strict-overflow '\n",
            "              '-Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override '\n",
            "              '-Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast '\n",
            "              '-Wno-missing-braces -fdiagnostics-color=always -faligned-new '\n",
            "              '-Wno-unused-but-set-variable -Wno-maybe-uninitialized '\n",
            "              '-fno-math-errno -fno-trapping-math -Werror=format '\n",
            "              '-Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, '\n",
            "              'PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.2.1, '\n",
            "              'USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, '\n",
            "              'USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, '\n",
            "              'USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, '\n",
            "              'USE_ROCM_KERNEL_ASSERT=OFF, \\n'),\n",
            "             ('TorchVision', '0.17.1+cu121'),\n",
            "             ('OpenCV', '4.8.0'),\n",
            "             ('MMEngine', '0.10.3')])\n"
          ]
        }
      ],
      "source": [
        "import platform\n",
        "from mmengine.utils.dl_utils import collect_env\n",
        "from pprint import pprint\n",
        "\n",
        "print(\"=\" * 40, \"System Information\", \"=\" * 40)\n",
        "uname = platform.uname()\n",
        "print(f\"System: {uname.system}\")\n",
        "print(f\"Node Name: {uname.node}\")\n",
        "print(f\"Release: {uname.release}\")\n",
        "print(f\"Version: {uname.version}\")\n",
        "print(f\"Machine: {uname.machine}\")\n",
        "print(f\"Processor: {uname.processor}\")\n",
        "\n",
        "print(\"=\" * 40, \"Environment Information\", \"=\" * 40)\n",
        "my_env = collect_env()\n",
        "pprint(my_env)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbwIB7N2G5-N"
      },
      "source": [
        "## General settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lWPPjI8wG5-N",
        "outputId": "ede90e63-9b96-43a2-e0e7-95f475c3d5f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightning_fabric.utilities.seed:Seed set to 42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda:0\n",
            "Number of workers: 2\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Path to the folder where the datasets are/should be downloaded (e.g. CIFAR10)\n",
        "DATASET_PATH = \"../data\"\n",
        "# Path to the folder where the pretrained models are saved\n",
        "CHECKPOINT_PATH = \"../checkpoints/ece763-proj_03\"\n",
        "\n",
        "# Setting the seed\n",
        "pl.seed_everything(42)\n",
        "# In this notebook, we use data loaders with heavier computational processing. It is recommended to use as many\n",
        "# workers as possible in a data loader, which corresponds to the number of CPU cores\n",
        "NUM_WORKERS = os.cpu_count()\n",
        "\n",
        "# Ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
        "torch.backends.cudnn.determinstic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(\"Device:\", device)\n",
        "print(\"Number of workers:\", NUM_WORKERS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jO59F5mpG5-N"
      },
      "source": [
        "# Get started with implementing SimCLR\n",
        "\n",
        "It is a method of self-supervised `contrastive` learning. Contrastive learning is motivated by the question mentioned above: how are images different from each other? Specifically, contrastive learning methods train a model to cluster an image and its slightly augmented version in latent space, while the distance to other images should be maximized. A very recent and simple method for this is [SimCLR](https://arxiv.org/abs/2006.10029), which is visualized below (figure credit - [Ting Chen et al.](https://simclr.github.io/)).\n",
        "\n",
        "<center width=\"100%\"><img src=\"figures/simclr_contrastive_learning.png\" width=\"500px\"></center>\n",
        "\n",
        "The general setup is that we are given a dataset of images without any labels, and want to train a model on this data such that it can quickly adapt to any image recognition task afterward. During each training iteration, we sample a batch of images as usual. For each image, we create two versions by applying data augmentation techniques like cropping, Gaussian noise, blurring, etc. An example of such is shown on the left with the image of the dog. We will go into the details and effects of the chosen augmentation techniques later. On those images, we apply a CNN like ResNet and obtain as output a 1D feature vector on which we apply a small MLP. The output features of the two augmented images are then trained to be close to each other, while all other images in that batch should be as different as possible. This way, the model has to learn to recognize the content of the image that remains unchanged under the data augmentations, such as objects which we usually care about in supervised tasks.\n",
        "\n",
        "We will now implement this framework ourselves and discuss further details along the way."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIM5DvrmG5-N"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikzz1y7iG5-N"
      },
      "source": [
        " We will use the [STL10 dataset](https://cs.stanford.edu/~acoates/stl10/), which, similarly to CIFAR10, contains images of 10 classes: `airplane, bird, car, cat, deer, dog, horse, monkey, ship, truck`. However, the images have a higher resolution, namely $96\\times 96$ pixels, and we are only provided with 500 labeled images per class. Additionally, we have a much larger set of $100,000$ unlabeled images which are similar to the training images but are sampled from a wider range of animals and vehicles. This makes the dataset ideal to showcase the benefits that self-supervised learning offers.\n",
        "\n",
        " However, to reduce the computationally complexity, we will downscale the images back to $32\\times 32$ pixels.  `Note: If you have sufficient GPU resources, you may try your implementation using` $96\\times 96$.\n",
        "\n",
        "Luckily, the STL10 dataset is provided through torchvision. Keep in mind, however, that since this dataset is relatively large and has a considerably higher resolution than CIFAR10, it requires more disk space (~3GB) and takes a bit of time to download. For our initial discussion of self-supervised learning and SimCLR, we will create two data loaders with our contrastive transformations above: the `unlabeled_data` will be used to train our model via contrastive learning, and `train_data_contrast` will be used as a validation set in contrastive learning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TL1vfOaRG5-O"
      },
      "source": [
        "### Data Augmentation for Contrastive Learning\n",
        "\n",
        "We will start our exploration of contrastive learning by discussing the effect of different data augmentation techniques, and how we can implement an efficient data loader for such. To allow efficient training, we need to prepare the data loading such that we sample two different, random augmentations for each image in the batch. The easiest way to do this is by creating a transformation that, when being called, applies a set of data augmentations to an image twice. This is implemented in the class `ContrastiveTransformations` below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "S2MowcYmG5-O"
      },
      "outputs": [],
      "source": [
        "class ContrastiveTransformations(object):\n",
        "\n",
        "    def __init__(self, base_transforms, n_views=2):\n",
        "        self.base_transforms = base_transforms\n",
        "        self.n_views = n_views\n",
        "\n",
        "    def __call__(self, x):\n",
        "        return [self.base_transforms(x) for i in range(self.n_views)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlwwVzpFG5-O"
      },
      "source": [
        "The contrastive learning framework can easily be extended to have more _positive_ examples by sampling more than two augmentations of the same image. However, the most efficient training is usually obtained by using only two.\n",
        "\n",
        "Next, we can look at the specific augmentations we want to apply. The choice of the data augmentation to use is the most crucial hyperparameter in SimCLR since it directly affects how the latent space is structured, and what patterns might be learned from the data. Let's first take a look at some of the most popular data augmentations (figure credit - [Ting Chen and Geoffrey Hinton](https://ai.googleblog.com/2020/04/advancing-self-supervised-and-semi.html)):\n",
        "\n",
        "<center width=\"100%\"><img src=\"figures/simclr_data_augmentations.png\" width=\"800px\" style=\"padding-top: 10px; padding-bottom: 10px\"></center>\n",
        "\n",
        "All of them can be used, but it turns out that two augmentations stand out in their importance: crop-and-resize, and color distortion. Interestingly, however, they only lead to strong performance if they have been used together as discussed by [Ting Chen et al.](https://arxiv.org/abs/2006.10029) in their SimCLR paper. When performing randomly cropping and resizing, we can distinguish between two situations: (a) cropped image A provides a local view of cropped image B, or (b) cropped images C and D show neighboring views of the same image (figure credit - [Ting Chen and Geoffrey Hinton](https://ai.googleblog.com/2020/04/advancing-self-supervised-and-semi.html)).\n",
        "\n",
        "<center width=\"100%\"><img src=\"figures/crop_views.svg\" width=\"400px\" style=\"padding-top: 20px; padding-bottom: 0px\"></center>\n",
        "\n",
        "While situation (a) requires the model to learn some sort of scale invariance to make crops A and B similar in latent space, situation (b) is more challenging since the model needs to recognize an object beyond its limited view. However, without color distortion, there is a loophole that the model can exploit, namely that different crops of the same image usually look very similar in color space. Consider the picture of the dog above. Simply from the color of the fur and the green color tone of the background, you can reason that two patches belong to the same image without actually recognizing the dog in the picture. In this case, the model might end up focusing only on the color histograms of the images, and ignore other more generalizable features. If, however, we distort the colors in the two patches randomly and independently of each other, the model cannot rely on this simple feature anymore. Hence, by combining random cropping and color distortions, the model can only match two patches by learning generalizable representations.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "rgWcFqlgG5-O"
      },
      "outputs": [],
      "source": [
        "# TODO data augmentaiton - [5 POINTS]\n",
        "# Overall, for our experiments, we apply a set of 5 transformations following the original SimCLR setup:\n",
        "# random horizontal flip,\n",
        "# crop-and-resize,\n",
        "# color distortion,\n",
        "# random grayscale,\n",
        "# and gaussian blur.\n",
        "# In comparison to the [original implementation](https://github.com/google-research/simclr),\n",
        "# we reduce the effect of the color jitter slightly (0.5 instead of 0.8 for brightness, contrast, and saturation, and 0.1 instead of 0.2 for hue).\n",
        "# In our experiments, this setting obtained better performance and was faster and more stable to train.\n",
        "# If, for instance, the brightness scale highly varies in a dataset, the original settings can be more beneficial\n",
        "# since the model can't rely on this information anymore to distinguish between images.\n",
        "#raise NotImplementedError\n",
        "contrast_transforms = transforms.Compose([transforms.RandomHorizontalFlip(),\n",
        "                                          transforms.RandomResizedCrop(size=32),\n",
        "                                          transforms.RandomApply([\n",
        "                                              transforms.ColorJitter(brightness=0.5,\n",
        "                                                                     contrast=0.5,\n",
        "                                                                     saturation=0.5,\n",
        "                                                                     hue=0.1)\n",
        "                                          ], p=0.8),\n",
        "                                          transforms.RandomGrayscale(p=0.2),\n",
        "                                          transforms.GaussianBlur(kernel_size=9),\n",
        "                                          transforms.ToTensor(),\n",
        "                                          transforms.Normalize((0.5,), (0.5,))\n",
        "                                         ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVCGpuY8G5-O",
        "outputId": "8bf075c7-a5e8-45c7-c2ef-e387c5817240"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://ai.stanford.edu/~acoates/stl10/stl10_binary.tar.gz to ../data/stl10_binary.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2640397119/2640397119 [01:42<00:00, 25704641.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data/stl10_binary.tar.gz to ../data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "unlabeled_data = STL10(root=DATASET_PATH, split='unlabeled', download=True,\n",
        "                       transform=ContrastiveTransformations(contrast_transforms, n_views=2))\n",
        "train_data_contrast = STL10(root=DATASET_PATH, split='train', download=True,\n",
        "                            transform=ContrastiveTransformations(contrast_transforms, n_views=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "49342f1adcb34775b4c57bb1934b1d31",
            "485abf8897bd4c7fb6a1520e6fc310f0",
            "631a8d12428949fbbe4828d20eaec1b4",
            "af9d1ca12c5a49928ad0169ad577de01",
            "fe09de4584874289aab4a61b78d4e42a",
            "ef786ecad5ee463883389ec122bda251",
            "82a8ab84e07f4dee9810af09852a8b68",
            "6d346421f8344d928342244db3a335e5",
            "3011955b675e494a8444e5ff1ef30410",
            "e41ce6b526534205a11b6f61b5a0ea3b",
            "d211c1765d2e4a2391c76a2409593ff3",
            "cd869a3fd4de46cf83ff925b3cf00242",
            "d2a9b11ae8ab4d22b0d0f826bf85bd51",
            "522becfd6c8245a9b43432006413c0bb",
            "ec8ae4f9e27942169bd95f9f75f7d177",
            "ce817f85db9a47dfbb56b32f9a60a2ee",
            "171839a10544421e8ce4f1e3a72b192d",
            "1610c7fc794e4d279b68abd03610e24e",
            "a1eebd013f694f59a6dc9c004a6148be",
            "8b2816d947ba411ba102b930403e143e",
            "03cb7e676f4d46e69b52bac345533408",
            "52d14b848e29445b98dcca0685179dd8"
          ]
        },
        "id": "3Pifoyz8G5-O",
        "outputId": "dbc5eaba-219c-4723-d51f-f6b8a1d22142"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "49342f1adcb34775b4c57bb1934b1d31"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/50 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cd869a3fd4de46cf83ff925b3cf00242"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Downscale images to 32x32 directly in arrays to save RAM and data loading computation\n",
        "def downscale_dataset(dataset):\n",
        "    data = dataset.data\n",
        "    num_imgs = data.shape[0]\n",
        "    new_data = np.zeros((num_imgs, data.shape[1], 32, 32), dtype=data.dtype)\n",
        "    for i in tqdm(range(0, num_imgs, 100)):\n",
        "        new_data[i:i+100] = transforms.functional.resize(torch.from_numpy(data[i:i+100]).float(), size=[32, 32]).to(torch.uint8).numpy()\n",
        "    dataset.data = new_data\n",
        "\n",
        "downscale_dataset(unlabeled_data)\n",
        "downscale_dataset(train_data_contrast)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hsq_ZVBYG5-O"
      },
      "source": [
        "Finally, before starting with our implementation of SimCLR, let's look at some example image pairs sampled with our augmentations:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "id": "NaNhPVTKG5-P",
        "outputId": "74c3a4c6-2be2-4fe2-be53-f693d28a1c1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightning_fabric.utilities.seed:Seed set to 42\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1400x700 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Visualize some examples\n",
        "pl.seed_everything(42)\n",
        "NUM_IMAGES = 6\n",
        "imgs = torch.stack([img for idx in range(NUM_IMAGES) for img in unlabeled_data[idx][0]], dim=0)\n",
        "img_grid = torchvision.utils.make_grid(imgs, nrow=6, normalize=True, pad_value=0.9)\n",
        "img_grid = img_grid.permute(1, 2, 0)\n",
        "\n",
        "plt.figure(figsize=(14,7))\n",
        "plt.title('Augmented image examples of the STL10 dataset', fontsize=20)\n",
        "plt.imshow(img_grid)\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqMyAvu_G5-P"
      },
      "source": [
        "We see the wide variety of our data augmentation, including randomly cropping, grayscaling, gaussian blur, and color distortion. Thus, it remains a challenging task for the model to match two, independently augmented patches of the same image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2wj6QChG5-P"
      },
      "source": [
        "## Part 1: SimCLR implementation\n",
        "\n",
        "Using the data loader pipeline above, we can now implement SimCLR. At each iteration, we get for every image $x$ two differently augmented versions, which we refer to as $\\tilde{x}_i$ and $\\tilde{x}_j$. Both of these images are encoded into a one-dimensional feature vector, between which we want to maximize similarity which minimizes it to all other images in the batch. The encoder network is split into two parts: a base encoder network $f(\\cdot)$, and a projection head $g(\\cdot)$. The base network is usually a deep CNN as we have seen before, and is responsible for extracting a representation vector from the augmented data examples. In our experiments, we will use a very simple `BaseNetwork` architecture as $f(\\cdot)$, and refer to the output as $f(\\tilde{x}_i)=h_i$. The projection head $g(\\cdot)$ maps the representation $h$ into a space where we apply the contrastive loss, i.e., compare similarities between vectors. It is often chosen to be a small MLP with non-linearities, and for simplicity, we follow the original SimCLR paper setup by defining it as a two-layer MLP with ReLU activation in the hidden layer. Note that in the follow-up paper, [SimCLRv2](https://arxiv.org/abs/2006.10029), the authors mention that larger/wider MLPs can boost the performance considerably. This is why we apply an MLP with four times larger hidden dimensions, but deeper MLPs showed to overfit on the given dataset. The general setup is visualized below (figure credit - [Ting Chen et al.](https://arxiv.org/abs/2006.10029)):\n",
        "\n",
        "<center width=\"100%\"><img src=\"figures/simclr_network_setup.svg\" width=\"350px\"></center>\n",
        "\n",
        "After finishing the training with contrastive learning, we will remove the projection head $g(\\cdot)$, and use $f(\\cdot)$ as a pretrained feature extractor. The representations $z$ that come out of the projection head $g(\\cdot)$ have been shown to perform worse than those of the base network $f(\\cdot)$ when finetuning the network for a new task. This is likely because the representations $z$ are trained to become invariant to many features like the color that can be important for downstream tasks. Thus, $g(\\cdot)$ is only needed for the contrastive learning stage.\n",
        "\n",
        "Let's first start by implementing a Base Network which will represent function $f(\\cdot)$. Usually, you would use very large, powerful networks like a deep ResNet, but these are very expensive to train. To reduce the computational cost and make it possible to train the models with limited computong resources, we provide a very simple CNN here:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "UXAXeFmRG5-P"
      },
      "outputs": [],
      "source": [
        "class BaseNetwork(nn.Module):\n",
        "\n",
        "    def __init__(self, num_input_channels, c_hid, output_dim):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "            - num_input_channels : Number of input channels of the image. For CIFAR, this parameter is 3\n",
        "            - c_hid : Number of channels we use in the first convolutional layers. Deeper layers might use a duplicate of it.\n",
        "            - output_dim : Dimensionality of the final latent representation\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(num_input_channels, c_hid, kernel_size=3, padding=1, stride=2), # 32x32 => 16x16\n",
        "            nn.BatchNorm2d(c_hid),\n",
        "            nn.SiLU(),\n",
        "            nn.Conv2d(c_hid, c_hid, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(c_hid),\n",
        "            nn.SiLU(),\n",
        "            nn.Conv2d(c_hid, 2*c_hid, kernel_size=3, padding=1, stride=2), # 16x16 => 8x8\n",
        "            nn.BatchNorm2d(2*c_hid),\n",
        "            nn.SiLU(),\n",
        "            nn.Conv2d(2*c_hid, 2*c_hid, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(2*c_hid),\n",
        "            nn.SiLU(),\n",
        "            nn.Conv2d(2*c_hid, 2*c_hid, kernel_size=3, padding=1, stride=2), # 8x8 => 4x4\n",
        "            nn.BatchNorm2d(2*c_hid),\n",
        "            nn.SiLU(),\n",
        "            nn.Flatten(), # Image grid to single feature vector\n",
        "            nn.Linear(2*16*c_hid, output_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WiKtAxpQG5-P"
      },
      "source": [
        "Now that the architecture is described, let's take a closer look at how we train the model. As mentioned before, we want to maximize the similarity between the representations of the two augmented versions of the same image, i.e., $z_i$ and $z_j$ in the figure above, while minimizing it to all other examples in the batch. SimCLR thereby applies the InfoNCE loss, originally proposed by [Aaron van den Oord et al.](https://arxiv.org/abs/1807.03748) for contrastive learning. In short, the InfoNCE loss compares the similarity of $z_i$ and $z_j$ to the similarity of $z_i$ to any other representation in the batch by performing a softmax over the similarity values. The loss can be formally written as:\n",
        "\n",
        "$$\n",
        "\\ell_{i,j}=-\\log \\frac{\\exp(\\text{sim}(z_i,z_j)/\\tau)}{\\sum_{k=1}^{2N}\\mathbb{1}_{[k\\neq i]}\\exp(\\text{sim}(z_i,z_k)/\\tau)}=-\\text{sim}(z_i,z_j)/\\tau+\\log\\left[\\sum_{k=1}^{2N}\\mathbb{1}_{[k\\neq i]}\\exp(\\text{sim}(z_i,z_k)/\\tau)\\right]\n",
        "$$\n",
        "\n",
        "The function $\\text{sim}$ is a similarity metric, and the hyperparameter $\\tau$ is called temperature determining how peaked the distribution is. Since many similarity metrics are bounded, the temperature parameter allows us to balance the influence of many dissimilar image patches versus one similar patch. The similarity metric that is used in SimCLR is cosine similarity, as defined below:\n",
        "\n",
        "$$\n",
        "\\text{sim}(z_i,z_j) = \\frac{z_i^\\top \\cdot z_j}{||z_i||\\cdot||z_j||}\n",
        "$$\n",
        "\n",
        "The maximum cosine similarity possible is $1$, while the minimum is $-1$. In general, we will see that the features of two different images will converge to a cosine similarity around zero since the minimum, $-1$, would require $z_i$ and $z_j$ to be in the exact opposite direction in all feature dimensions, which does not allow for great flexibility.\n",
        "\n",
        "Finally, now that we have discussed all details, let's implement SimCLR below as a PyTorch Lightning module:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "BbtiNYXUG5-P"
      },
      "outputs": [],
      "source": [
        "class SimCLR(pl.LightningModule):\n",
        "\n",
        "    def __init__(self, hidden_dim, lr, temperature, weight_decay, max_epochs=500):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "        assert self.hparams.temperature > 0.0, 'The temperature must be a positive float!'\n",
        "        # TODO: Setup the Base Network [5 POINTS]\n",
        "        #raise NotImplementedError\n",
        "        # Base model f(.)\n",
        "        self.convnet = BaseNetwork(num_input_channels=3, c_hid=hidden_dim, output_dim=4*hidden_dim)\n",
        "        # The MLP for g(.) consists of Linear->ReLU->Linear\n",
        "\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = optim.AdamW(self.parameters(),\n",
        "                                lr=self.hparams.lr,\n",
        "                                weight_decay=self.hparams.weight_decay)\n",
        "        lr_scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer,\n",
        "                                                            T_max=self.hparams.max_epochs,\n",
        "                                                            eta_min=self.hparams.lr/50)\n",
        "        return [optimizer], [lr_scheduler]\n",
        "\n",
        "    def info_nce_loss(self, batch, mode='train'):\n",
        "        imgs, _ = batch  # we do not need the labels here\n",
        "        # imgs is a list of length 2, where imgs[0][i] and imgs[1][i] are the positive pairs\n",
        "\n",
        "        # TODO: Calculate the contrastive loss of SimCLR. Try to be as efficient as possible [20 POINTS]\n",
        "        # Hint: if you add imgs into a batch where over dimension 0, you have [imgs[0],imgs[1]],\n",
        "        # the positive pair for an image at position i is always at (i + batch_size) % (2 * batch_size)\n",
        "        # Can you create a mask to find the positive element for each batch element?\n",
        "        #raise NotImplementedError\n",
        "\n",
        "        #START HERE\n",
        "        imgs = torch.cat(imgs, dim=0)\n",
        "        # Encode all images\n",
        "        feats = self.convnet(imgs)\n",
        "        # Calculate cosine similarity\n",
        "        cos_sim = F.cosine_similarity(feats[:,None,:], feats[None,:,:], dim=-1)\n",
        "        # Mask out cosine similarity to itself\n",
        "        self_mask = torch.eye(cos_sim.shape[0], dtype=torch.bool, device=cos_sim.device)\n",
        "        cos_sim.masked_fill_(self_mask, -9e15)\n",
        "        # Find positive example -> batch_size//2 away from the original example\n",
        "        pos_mask = self_mask.roll(shifts=cos_sim.shape[0]//2, dims=0)\n",
        "        # InfoNCE loss\n",
        "        cos_sim = cos_sim / self.hparams.temperature\n",
        "        loss = -cos_sim[pos_mask] + torch.logsumexp(cos_sim, dim=-1)\n",
        "        loss = loss.mean()\n",
        "\n",
        "        # Logging loss\n",
        "        self.log(mode+'_loss', loss)\n",
        "        # Get ranking position of positive example\n",
        "        comb_sim = torch.cat([cos_sim[pos_mask][:,None],  # First position positive example\n",
        "                              cos_sim.masked_fill(pos_mask, -9e15)],\n",
        "                             dim=-1)\n",
        "        sim_argsort = comb_sim.argsort(dim=-1, descending=True).argmin(dim=-1)\n",
        "        #END HERE\n",
        "\n",
        "        # Log the loss and the top-1 and top-5 accuracy as how often the most similar image was the positive\n",
        "        self.log(mode + \"_acc_top1\", (sim_argsort == 0).float().mean())\n",
        "        self.log(mode + \"_acc_top5\", (sim_argsort < 5).float().mean())\n",
        "        self.log(mode + \"_acc_mean_pos\", 1 + sim_argsort.float().mean())\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        return self.info_nce_loss(batch, mode='train')\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        self.info_nce_loss(batch, mode='val')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWx3_vwxG5-Q"
      },
      "source": [
        "### Training\n",
        "\n",
        "Now that we have implemented SimCLR and the data loading pipeline, we are ready to train the model. We will use the same training function setup as usual. For saving the best model checkpoint, we track the metric `val_acc_top5`, which describes how often the correct image patch is within the top-5 most similar examples in the batch. This is usually less noisy than the top-1 metric, making it a better metric to choose the best model from."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "AvDR8_mhG5-Q"
      },
      "outputs": [],
      "source": [
        "def train_simclr(batch_size, max_epochs=500, **kwargs):\n",
        "    trainer = pl.Trainer(default_root_dir=os.path.join(CHECKPOINT_PATH, 'SimCLR'),\n",
        "                         accelerator=\"gpu\" if str(device).startswith(\"cuda\") else \"cpu\",\n",
        "                         devices=1,\n",
        "                         max_epochs=max_epochs,\n",
        "                         callbacks=[ModelCheckpoint(save_weights_only=True, mode='max', monitor='val_acc_top5'),\n",
        "                                    LearningRateMonitor('epoch')],\n",
        "                         check_val_every_n_epoch=5)\n",
        "    trainer.logger._default_hp_metric = None # Optional logging argument that we don't need\n",
        "\n",
        "    # Check whether pretrained model exists. If yes, load it and skip training\n",
        "    pretrained_filename = os.path.join(CHECKPOINT_PATH, 'SimCLR.ckpt')\n",
        "    if os.path.isfile(pretrained_filename):\n",
        "        print(f'Found pretrained model at {pretrained_filename}, loading...')\n",
        "        model = SimCLR.load_from_checkpoint(pretrained_filename) # Automatically loads the model with the saved hyperparameters\n",
        "    else:\n",
        "        train_loader = data.DataLoader(unlabeled_data, batch_size=batch_size, shuffle=True,\n",
        "                                       drop_last=True, pin_memory=True, num_workers=NUM_WORKERS)\n",
        "        val_loader = data.DataLoader(train_data_contrast, batch_size=batch_size, shuffle=False,\n",
        "                                     drop_last=False, pin_memory=True, num_workers=NUM_WORKERS,persistent_workers=True)\n",
        "        pl.seed_everything(42) # To be reproducable\n",
        "        model = SimCLR(max_epochs=max_epochs, **kwargs)\n",
        "        trainer.fit(model, train_loader, val_loader)\n",
        "        model = SimCLR.load_from_checkpoint(trainer.checkpoint_callback.best_model_path) # Load best checkpoint after training\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zE2mWxTsG5-Q"
      },
      "source": [
        "A common observation in contrastive learning is that the larger the batch size, the better the models perform. A larger batch size allows us to compare each image to more negative examples, leading to overall smoother loss gradients, but a batch size of 256 is sufficient here. Again, for a first run, you can use 10 epochs, but try to increase the number of epochs for a final run."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 755,
          "referenced_widgets": [
            "b969f6ebabe04d1da7a5df245b0afd41",
            "da8d44d2cb5949ec8c875238ec70445d",
            "237c654bc78549ca854fe96ef75a844e",
            "928f8bfbc9714fe09c1b5eaee5dd1577",
            "2b678cc5ff7b4cff9d96cf1078fa08f7",
            "e16afdd57341497fb96fc21d2d4aa4cd",
            "38409d162dc1497c89a11b8b8c9c38d4",
            "02d7115a012d4de78bfa32118e7a8ed8",
            "d809c0b57074454b9bcb20662f6bf8de",
            "a1b5410b1fea4c6b889f70782b56fba2",
            "135d6f1c4531467ea52ad0bbb02e09ab",
            "c2b8ca9b0a8340daa70f10b0a5721106",
            "f69d28c07bd54db49ef0a3e167b6c410",
            "bdbd339ae5fe41139e4fc0db10d8d298",
            "1c069fc5295f43e0bfa22881aa233f05",
            "5f4f662acc3144f39ab11d5e266960ca",
            "a887f045d2504205991ce6dde8c23e2b",
            "0cf091503fa04b16b28216e3bda7b26d",
            "c8c011993d3b43dca560864d4444e18e",
            "515f5948130a458c8c2e01a75733b95f",
            "2277882dc8d0454b8e3fbcde196cdfcd",
            "7088a5234c5745b6ad2f53127a89b861"
          ]
        },
        "id": "RpvFjOu2G5-Q",
        "outputId": "84e0670a-0d35-4489-c1a8-e93e175b80b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:lightning_fabric.utilities.seed:Seed set to 42\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name    | Type        | Params\n",
            "----------------------------------------\n",
            "0 | convnet | BaseNetwork | 3.7 M \n",
            "----------------------------------------\n",
            "3.7 M     Trainable params\n",
            "0         Non-trainable params\n",
            "3.7 M     Total params\n",
            "14.905    Total estimated model params size (MB)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b969f6ebabe04d1da7a5df245b0afd41"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c2b8ca9b0a8340daa70f10b0a5721106"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IsADirectoryError",
          "evalue": "[Errno 21] Is a directory: '/content'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIsADirectoryError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-214be6c32cf2>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m simclr_model = train_simclr(batch_size=256, \n\u001b[0m\u001b[1;32m      2\u001b[0m                             \u001b[0mhidden_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                             \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5e-4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                             \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.07\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                             \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-8fd27f77e1eb>\u001b[0m in \u001b[0;36mtrain_simclr\u001b[0;34m(batch_size, max_epochs, **kwargs)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSimCLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSimCLR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_from_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint_callback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_model_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Load best checkpoint after training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/model_helpers.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m                     \u001b[0;34m\" Please call it on the class type and make sure the return value is used.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m                 )\n\u001b[0;32m--> 125\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/module.py\u001b[0m in \u001b[0;36mload_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[1;32m   1579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1580\u001b[0m         \"\"\"\n\u001b[0;32m-> 1581\u001b[0;31m         loaded = _load_from_checkpoint(\n\u001b[0m\u001b[1;32m   1582\u001b[0m             \u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1583\u001b[0m             \u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/saving.py\u001b[0m in \u001b[0;36m_load_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mmap_location\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap_location\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_default_map_location\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mpl_legacy_patch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpl_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmap_location\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;31m# convert legacy checkpoints to the new format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightning_fabric/utilities/cloud_io.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(path_or_url, map_location)\u001b[0m\n\u001b[1;32m     54\u001b[0m         )\n\u001b[1;32m     55\u001b[0m     \u001b[0mfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_filesystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmap_location\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/fsspec/spec.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, path, mode, block_size, cache_options, compression, **kwargs)\u001b[0m\n\u001b[1;32m   1239\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1240\u001b[0m             \u001b[0mac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"autocommit\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_intrans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1241\u001b[0;31m             f = self._open(\n\u001b[0m\u001b[1;32m   1242\u001b[0m                 \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/fsspec/implementations/local.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, path, mode, block_size, **kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_mkdir\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"w\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mLocalFileOpener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtouch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/fsspec/implementations/local.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, mode, autocommit, fs, compression, **kwargs)\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompression\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_compression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocksize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFAULT_BUFFER_SIZE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/fsspec/implementations/local.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclosed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocommit\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"w\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m                     \u001b[0mcompress\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIsADirectoryError\u001b[0m: [Errno 21] Is a directory: '/content'"
          ]
        }
      ],
      "source": [
        "simclr_model = train_simclr(batch_size=256,\n",
        "                            hidden_dim=128,\n",
        "                            lr=5e-4,\n",
        "                            temperature=0.07,\n",
        "                            weight_decay=1e-4,\n",
        "                            max_epochs=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "el_s1GIlG5-Q"
      },
      "source": [
        "To get an intuition of how training with contrastive learning behaves, we can take a look at the TensorBoard below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kT7KYGFsG5-Q"
      },
      "outputs": [],
      "source": [
        "%tensorboard --logdir ../checkpoints/ece763-proj_03/SimCLR/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FcjRiOuG5-R"
      },
      "source": [
        "In your report, show the top-1 and top-5 accuracy validation curves. Discuss the overall performance and the training speed. Is the model already converged? What does the final performance of the model imply about the learned feature space?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSQrluXRG5-R"
      },
      "source": [
        "## Part 2: Logistic Regression\n",
        "\n",
        "After we have trained our model via contrastive learning, we can deploy it on downstream tasks and see how well it performs with little data. A common setup, which also verifies whether the model has learned generalized representations, is to perform Logistic Regression on the features. In other words, we learn a single, linear layer that maps the representations to a class prediction. Since the base network $f(\\cdot)$ is not changed during the training process, the model can only perform well if the representations of $h$ describe all features that might be necessary for the task. Further, we do not have to worry too much about overfitting since we have very few parameters that are trained. Hence, we might expect that the model can perform well even with very little data.\n",
        "\n",
        "First, let's implement a simple Logistic Regression setup for which we assume that the images already have been encoded in their feature vectors. If very little data is available, it might be beneficial to dynamically encode the images during training so that we can also apply data augmentations. However, the way we implement it here is much more efficient and can be trained within a few seconds. Further, using data augmentations did not show any significant gain in this simple setup."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "pBVdoWm6G5-R"
      },
      "outputs": [],
      "source": [
        "class LogisticRegression(pl.LightningModule):\n",
        "\n",
        "    def __init__(self, feature_dim, num_classes, lr, weight_decay, max_epochs=100):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "        # Mapping from representation h to classes\n",
        "        # Initialize logistic regression model\n",
        "        self.model = nn.Linear(feature_dim, num_classes)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = optim.AdamW(self.parameters(),\n",
        "                                lr=self.hparams.lr,\n",
        "                                weight_decay=self.hparams.weight_decay)\n",
        "        lr_scheduler = optim.lr_scheduler.MultiStepLR(optimizer,\n",
        "                                                      milestones=[int(self.hparams.max_epochs*0.6),\n",
        "                                                                  int(self.hparams.max_epochs*0.8)],\n",
        "                                                      gamma=0.1)\n",
        "        return [optimizer], [lr_scheduler]\n",
        "\n",
        "    def _calculate_loss(self, batch, mode='train'):\n",
        "        # TODO: Calculate classification loss for logistic regression model [5 POINTS]\n",
        "        #raise NotImplementedError\n",
        "        feats, labels = batch\n",
        "        preds = self.model(feats)\n",
        "        loss = F.cross_entropy(preds, labels)\n",
        "        acc = (preds.argmax(dim=-1) == labels).float().mean()\n",
        "\n",
        "        self.log(mode + \"_loss\", loss)\n",
        "        self.log(mode + \"_acc\", acc)\n",
        "        return loss\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        return self._calculate_loss(batch, mode='train')\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        self._calculate_loss(batch, mode='val')\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        self._calculate_loss(batch, mode='test')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcoR74g-G5-R"
      },
      "source": [
        "The data we use is the training and test set of STL10. The training contains 500 images per class, while the test set has 800 images per class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150,
          "referenced_widgets": [
            "3bb408e506ab48ae92de8e4b154788a0",
            "e0b9b5ee84644289a5ce531f5d267c67",
            "3c84a130ec2048e0b70c234c27ab4543",
            "18a830bfb0ae4397b74ce1a93a2edf5a",
            "adcb81064a1342168712555ecac8fdc5",
            "ba1db6d80cb1407fa892f99b256a37e0",
            "73a175fdb1334f048d4495c1cf66c10b",
            "1fabd1996ba348e5a6f236c9d86bacdd",
            "aa79f19011c247fca3abbcda27c68877",
            "040b7ad81034402ea57b0656e63b9e05",
            "546a08d7c2644457b41714cc99bb5e34",
            "3a83d312b0304ca28a56bb4aa6a5eb3c",
            "4199ef86cf374429a1938384d5925c92",
            "e414eb5c487a42aea93c927ab1920202",
            "378476a1756a48c2a93b7b2fc38eed78",
            "0c454c8f17c84df08eab670b77e02b5e",
            "7dae7f51d52b4621b525cf5d32aca92e",
            "1c9a78e9c5824255a3a4ca7336a0a5c0",
            "edd3552cc97348c5993d09d41117d57c",
            "034465d7bcf248d3847c2a50a336492d",
            "b00e5dc8945f49459e18ab9131925284",
            "0759bc89c3464071817bbe3fd1698096"
          ]
        },
        "id": "P6otiNeeG5-R",
        "outputId": "8993f104-3764-4e69-af0c-8c831bcd6543"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/50 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3bb408e506ab48ae92de8e4b154788a0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/80 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3a83d312b0304ca28a56bb4aa6a5eb3c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training examples: 5000\n",
            "Number of test examples: 8000\n"
          ]
        }
      ],
      "source": [
        "img_transforms = transforms.Compose([transforms.ToTensor(),\n",
        "                                     transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "train_img_data = STL10(root=DATASET_PATH, split='train', download=True,\n",
        "                       transform=img_transforms)\n",
        "test_img_data = STL10(root=DATASET_PATH, split='test', download=True,\n",
        "                      transform=img_transforms)\n",
        "downscale_dataset(train_img_data)\n",
        "downscale_dataset(test_img_data)\n",
        "\n",
        "print(\"Number of training examples:\", len(train_img_data))\n",
        "print(\"Number of test examples:\", len(test_img_data))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "892Ein-4G5-R"
      },
      "source": [
        "Next, we implement a small function to encode all images in our datasets. The output representations are then used as inputs to the Logistic Regression model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "FvqdrPo3G5-S"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def prepare_data_features(model, dataset):\n",
        "    # TODO: Obtain the feature representation for all images in the dataset [5 POINTS]\n",
        "    #raise NotImplementedError\n",
        "    network = deepcopy(model.encoder)\n",
        "    network.eval()\n",
        "    network.to(device)\n",
        "\n",
        "    # Encode all images\n",
        "    data_loader = data.DataLoader(dataset, batch_size=64, num_workers=NUM_WORKERS, shuffle=False, drop_last=False)\n",
        "    feats, labels = [], []\n",
        "    for batch_imgs, batch_labels in tqdm(data_loader):\n",
        "        batch_imgs = batch_imgs.to(device)\n",
        "        batch_feats = network(batch_imgs)\n",
        "        feats.append(batch_feats.detach().cpu())\n",
        "        labels.append(batch_labels)\n",
        "\n",
        "    feats = torch.cat(feats, dim=0)\n",
        "    labels = torch.cat(labels, dim=0)\n",
        "\n",
        "    # Sort images by labels\n",
        "    labels, idxs = labels.sort()\n",
        "    feats = feats[idxs]\n",
        "\n",
        "    # Return a new dataset with the image features and labels\n",
        "    return data.TensorDataset(feats, labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPjjr-EMG5-S"
      },
      "source": [
        "Let's apply the function to both training and test set below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AXa95A0HG5-T"
      },
      "outputs": [],
      "source": [
        "train_feats_simclr = prepare_data_features(simclr_model, train_img_data)\n",
        "test_feats_simclr = prepare_data_features(simclr_model, test_img_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nxfpkjo6G5-T"
      },
      "source": [
        "Finally, we can write a training function as usual. We evaluate the model on the test set every 10 epochs to allow early stopping, but the low frequency of the validation ensures that we do not overfit too much on the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rlgqfKShG5-T"
      },
      "outputs": [],
      "source": [
        "def train_logreg(batch_size, train_feats_data, test_feats_data, model_suffix, max_epochs=100, **kwargs):\n",
        "    trainer = pl.Trainer(\n",
        "        default_root_dir=os.path.join(CHECKPOINT_PATH, \"LogisticRegression\"),\n",
        "        accelerator=\"gpu\" if str(device).startswith(\"cuda\") else \"cpu\",\n",
        "        devices=1,\n",
        "        max_epochs=max_epochs,\n",
        "        callbacks=[\n",
        "            ModelCheckpoint(save_weights_only=True, mode=\"max\", monitor=\"val_acc\"),\n",
        "            LearningRateMonitor(\"epoch\"),\n",
        "        ],\n",
        "        enable_progress_bar=False,\n",
        "        check_val_every_n_epoch=10,\n",
        "    )\n",
        "    trainer.logger._default_hp_metric = None\n",
        "\n",
        "    # Data loaders\n",
        "    train_loader = data.DataLoader(train_feats_data, batch_size=batch_size, shuffle=True,\n",
        "                                   drop_last=False, pin_memory=True, num_workers=0)\n",
        "    test_loader = data.DataLoader(test_feats_data, batch_size=batch_size, shuffle=False,\n",
        "                                  drop_last=False, pin_memory=True, num_workers=0)\n",
        "\n",
        "    # Check whether pretrained model exists. If yes, load it and skip training\n",
        "    pretrained_filename = os.path.join(CHECKPOINT_PATH, f\"LogisticRegression_{model_suffix}.ckpt\")\n",
        "    if os.path.isfile(pretrained_filename):\n",
        "        print(f\"Found pretrained model at {pretrained_filename}, loading...\")\n",
        "        model = LogisticRegression.load_from_checkpoint(pretrained_filename)\n",
        "    else:\n",
        "        pl.seed_everything(42)  # To be reproducable\n",
        "        model = LogisticRegression(**kwargs)\n",
        "        trainer.fit(model, train_loader, test_loader)\n",
        "        model = LogisticRegression.load_from_checkpoint(trainer.checkpoint_callback.best_model_path)\n",
        "\n",
        "    # Test best model on train and validation set\n",
        "    train_result = trainer.test(model, train_loader, verbose=False)\n",
        "    test_result = trainer.test(model, test_loader, verbose=False)\n",
        "    result = {\"train\": train_result[0][\"test_acc\"], \"test\": test_result[0][\"test_acc\"]}\n",
        "\n",
        "    return model, result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mT7CqPBvG5-T"
      },
      "source": [
        "Despite the training dataset of STL10 already only having 500 labeled images per class, we will perform experiments with even smaller datasets. Specifically, we train a Logistic Regression model for datasets with only 10, 20, 50, 100, 200, and all 500 examples per class. This gives us an intuition on how well the representations learned by contrastive learning can be transfered to a image recognition task like this classification. First, let's define a function to create the intended sub-datasets from the full training set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i7DcNEkkG5-T"
      },
      "outputs": [],
      "source": [
        "def get_smaller_dataset(original_dataset, num_imgs_per_label):\n",
        "    # TODO: Return dataset with the first N images per label [5 POINTS]\n",
        "    #raise NotImplementedError\n",
        "    new_dataset = data.TensorDataset(\n",
        "        *[t.unflatten(0, (10, -1))[:,:num_imgs_per_label].flatten(0, 1) for t in original_dataset.tensors]\n",
        "    )\n",
        "    return new_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULZ-wol7G5-T"
      },
      "source": [
        "Next, let's run all models. Despite us training 6 models, this cell could be run within a minute or two without the pretrained models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "tuboo1h8G5-T"
      },
      "outputs": [],
      "source": [
        "# TODO: Run the logistic regression on datasets of 10, 20, 50, 100, 200, and 500 labeled examples [5 POINTS]\n",
        "#raise NotImplementedError\n",
        "results = {}\n",
        "for num_imgs_per_label in [10, 20, 50, 100, 200, 500]:\n",
        "\n",
        "  sub_train_set = get_smaller_dataset(train_feats_simclr, num_imgs_per_label)\n",
        "  _, small_set_results = train_logreg(batch_size=64,\n",
        "                                        train_feats_data=sub_train_set,\n",
        "                                        test_feats_data=test_feats_simclr,\n",
        "                                        model_suffix=num_imgs_per_label,\n",
        "                                        feature_dim=train_feats_simclr.tensors[0].shape[1],\n",
        "                                        num_classes=10,\n",
        "                                        lr=1e-3,\n",
        "                                        weight_decay=1e-3)\n",
        "\n",
        "  results[num_imgs_per_label] = small_set_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K53rMgkjG5-T"
      },
      "source": [
        "Finally, let's plot the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qBXxT-IrG5-U"
      },
      "outputs": [],
      "source": [
        "# Plot the results\n",
        "\n",
        "dataset_sizes = sorted([k for k in results])\n",
        "test_scores = [results[k][\"test\"] for k in dataset_sizes]\n",
        "\n",
        "fig = plt.figure(figsize=(6, 4))\n",
        "plt.plot(\n",
        "    dataset_sizes,\n",
        "    test_scores,\n",
        "    \"--\",\n",
        "    color=\"#000\",\n",
        "    marker=\"*\",\n",
        "    markeredgecolor=\"#000\",\n",
        "    markerfacecolor=\"y\",\n",
        "    markersize=16,\n",
        ")\n",
        "plt.xscale(\"log\")\n",
        "plt.xticks(dataset_sizes, labels=dataset_sizes)\n",
        "plt.title(\"STL10 classification over dataset size\", fontsize=14)\n",
        "plt.xlabel(\"Number of images per class\")\n",
        "plt.ylabel(\"Test accuracy\")\n",
        "plt.minorticks_off()\n",
        "plt.show()\n",
        "\n",
        "for k, score in zip(dataset_sizes, test_scores):\n",
        "    print(f\"Test accuracy for {k:3d} images per label: {100*score:4.2f}%\")\n",
        "\n",
        "\n",
        "# We should observe performance similar\n",
        "# Test accuracy for  10 images per label: 40.09%\n",
        "# Test accuracy for  20 images per label: 43.75%\n",
        "# Test accuracy for  50 images per label: 48.66%\n",
        "# Test accuracy for 100 images per label: 52.79%\n",
        "# Test accuracy for 200 images per label: 55.26%\n",
        "# Test accuracy for 500 images per label: 58.28%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mj-6RqLDG5-U"
      },
      "source": [
        "TODO: [5 POINTS] Discuss the overall performance as well as the trend you see in the plot. Where do you see the biggest jump in performance? Is the performance already saturating?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jI-PNcoTG5-U"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tS64o1OrG5-U"
      },
      "source": [
        "## Part 3: Baseline\n",
        "\n",
        "As a baseline to our results above, we will train the BaseNetwork with random initialization on the labeled training set of STL10. The results will give us an indication of the advantages that contrastive learning on unlabeled data has compared to using only supervised training. First, let's implement it below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rvOjauQvG5-U"
      },
      "outputs": [],
      "source": [
        "class Baseline(pl.LightningModule):\n",
        "\n",
        "    def __init__(self, num_classes, lr, weight_decay, max_epochs=100):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "        # Initialize a base network\n",
        "        self.model = BaseNetwork(num_input_channels=3, c_hid=48, output_dim=num_classes)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = optim.AdamW(self.parameters(),\n",
        "                                lr=self.hparams.lr,\n",
        "                                weight_decay=self.hparams.weight_decay)\n",
        "        lr_scheduler = optim.lr_scheduler.MultiStepLR(optimizer,\n",
        "                                                      milestones=[int(self.hparams.max_epochs*0.7),\n",
        "                                                                  int(self.hparams.max_epochs*0.9)],\n",
        "                                                      gamma=0.1)\n",
        "        return [optimizer], [lr_scheduler]\n",
        "\n",
        "    def _calculate_loss(self, batch, mode='train'):\n",
        "        # TODO: Calculate classification loss and accuracy [5 points]\n",
        "        #raise NotImplementedError\n",
        "\n",
        "        imgs, labels = batch\n",
        "        preds = self.model(imgs)\n",
        "        loss = F.cross_entropy(preds, labels)\n",
        "        acc = (preds.argmax(dim=-1) == labels).float().mean()\n",
        "\n",
        "        self.log(mode + \"_loss\", loss)\n",
        "        self.log(mode + \"_acc\", acc)\n",
        "        return loss\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        return self._calculate_loss(batch, mode='train')\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        self._calculate_loss(batch, mode='val')\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        self._calculate_loss(batch, mode='test')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhsiBPjPG5-U"
      },
      "source": [
        "It is clear that the ResNet easily overfits on the training data since its parameter count is more than 1000 times larger than the dataset size. To make the comparison to the contrastive learning models fair, we apply data augmentations similar to the ones we used before: horizontal flip, crop-and-resize, grayscale, and gaussian blur. Color distortions as before are not used because the color distribution of an image showed to be an important feature for the classification. Hence, we observed no noticeable performance gains when adding color distortions to the set of augmentations. Similarly, we restrict the resizing operation before cropping to the max. 125% of its original resolution, instead of 1250% as done in SimCLR. This is because, for classification, the model needs to recognize the full object, while in contrastive learning, we only want to check whether two patches belong to the same image/object. Hence, the chosen augmentations below are overall weaker than in the contrastive learning case."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "25K9kXH6G5-U"
      },
      "outputs": [],
      "source": [
        "train_transforms = transforms.Compose([transforms.RandomHorizontalFlip(),\n",
        "                                       transforms.RandomResizedCrop(size=32, scale=(0.8, 1.0)),\n",
        "                                       transforms.RandomGrayscale(p=0.2),\n",
        "                                       transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 0.5)),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize((0.5,), (0.5,))\n",
        "                                       ])\n",
        "\n",
        "train_img_aug_data = STL10(root=DATASET_PATH, split='train', download=True,\n",
        "                           transform=train_transforms)\n",
        "downscale_dataset(train_img_aug_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwgawizpG5-U"
      },
      "source": [
        "The training function for the BaseNetwork is almost identical to the Logistic Regression setup. Note that we allow the BaseNetwork to perform validation every 2 epochs to also check whether the model overfits strongly in the first iterations or not."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sn7e5ApCG5-V"
      },
      "outputs": [],
      "source": [
        "def train_baseline(batch_size, max_epochs=100, **kwargs):\n",
        "    trainer = pl.Trainer(\n",
        "        default_root_dir=os.path.join(CHECKPOINT_PATH, \"ResNet\"),\n",
        "        accelerator=\"gpu\" if str(device).startswith(\"cuda\") else \"cpu\",\n",
        "        devices=1,\n",
        "        max_epochs=max_epochs,\n",
        "        callbacks=[\n",
        "            ModelCheckpoint(save_weights_only=True, mode=\"max\", monitor=\"val_acc\"),\n",
        "            LearningRateMonitor(\"epoch\"),\n",
        "        ],\n",
        "        enable_progress_bar=False,\n",
        "        check_val_every_n_epoch=2,\n",
        "    )\n",
        "    trainer.logger._default_hp_metric = None\n",
        "\n",
        "    # Data loaders\n",
        "    train_loader = data.DataLoader(train_img_aug_data, batch_size=batch_size, shuffle=True,\n",
        "                                   drop_last=True, pin_memory=True, num_workers=NUM_WORKERS)\n",
        "    test_loader = data.DataLoader(test_img_data, batch_size=batch_size, shuffle=False,\n",
        "                                  drop_last=False, pin_memory=True, num_workers=NUM_WORKERS)\n",
        "\n",
        "    # Check whether pretrained model exists. If yes, load it and skip training\n",
        "    pretrained_filename = os.path.join(CHECKPOINT_PATH, \"ResNet.ckpt\")\n",
        "    if os.path.isfile(pretrained_filename):\n",
        "        print(\"Found pretrained model at %s, loading...\" % pretrained_filename)\n",
        "        model = Baseline.load_from_checkpoint(pretrained_filename)\n",
        "    else:\n",
        "        pl.seed_everything(42) # To be reproducable\n",
        "        model = Baseline(**kwargs)\n",
        "        trainer.fit(model, train_loader, test_loader)\n",
        "        model = Baseline.load_from_checkpoint(trainer.checkpoint_callback.best_model_path)\n",
        "\n",
        "    # Test best model on validation set\n",
        "    train_result = trainer.test(model, train_loader, verbose=False)\n",
        "    val_result = trainer.test(model, test_loader, verbose=False)\n",
        "    result = {\"train\": train_result[0][\"test_acc\"], \"test\": val_result[0][\"test_acc\"]}\n",
        "\n",
        "    return model, result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASnLDbbGG5-V"
      },
      "source": [
        "Finally, let's train the model and check its results. For a first run, use 10 epochs, but to obtain final results, try to train the model on more epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "_aqHD-pGG5-V"
      },
      "outputs": [],
      "source": [
        "baseline_model, baseline_result = train_baseline(batch_size=64,\n",
        "                                               num_classes=10,\n",
        "                                               lr=1e-3,\n",
        "                                               weight_decay=2e-4,\n",
        "                                               max_epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pzjhb_xKG5-V"
      },
      "outputs": [],
      "source": [
        "print(f\"Accuracy on training set: {baseline_result['train']:.2%}\")\n",
        "print(f\"Accuracy on test set: {baseline_result['test']:.2%}\")\n",
        "\n",
        "# We should observe performance similar to\n",
        "# Accuracy on training set: 67.03%\n",
        "# Accuracy on test set: 60.29%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgyikahxG5-V"
      },
      "source": [
        "TODO: [5 POINTS] Discuss the results you have obtained from this baseline and compare it to the logistic regression model in Part 2. What do you see? What do the results imply?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xd0MW4PiG5-V"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CGNTVPjG5-V"
      },
      "source": [
        "## Summary of SimCLR\n",
        "\n",
        "We have discussed self-supervised contrastive learning and implemented SimCLR as an example method. We have applied it to the STL10 dataset and showed that it can learn generalizable representations that we can use to train simple classification models. Besides the discussed hyperparameters, the size of the model seems to be important in contrastive learning as well. If a lot of unlabeled data is available, larger models can achieve much stronger results and come close to their supervised baselines. Further, there are also approaches for combining contrastive and supervised learning, leading to performance gains beyond supervision (see [Khosla et al.](https://arxiv.org/abs/2004.11362)).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZnBVUWbG5-V"
      },
      "source": [
        "# Explore Another SSL Method\n",
        "\n",
        "Moreover, contrastive learning is not the only approach to self-supervised learning that has come up in the last two years and showed great results. Other methods include distillation-based methods like [BYOL](https://arxiv.org/abs/2006.07733), [SimSiam](https://arxiv.org/abs/2011.10566) and redundancy reduction techniques like [Barlow Twins](https://arxiv.org/abs/2103.03230). There is a lot more to explore in the self-supervised domain as briefly discssed in our lecture.\n",
        "\n",
        "\n",
        "Implement `BYOL` or `SimSiam` or `BarlowTwins` to replace the SimCLR in Part 1 above, and re-do the experiments in Part 1 and Part 2.  With your new SSL method, compare with SimCLR and the baseline in Part 3."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wSFYud2FG5-V"
      },
      "outputs": [],
      "source": [
        "# Modify the interface as you see fit\n",
        "\n",
        "class AnotherSSL(pl.LightningModule):\n",
        "\n",
        "    def __init__(self, hidden_dim, lr, temperature, weight_decay, max_epochs=500):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "        assert (\n",
        "            self.hparams.temperature > 0.0\n",
        "        ), \"The temperature must be a positive float!\"\n",
        "        # TODO: Setup the Base Network [5 POINTS]\n",
        "        raise NotImplementedError\n",
        "\n",
        "\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = optim.AdamW(\n",
        "            self.parameters(),\n",
        "            lr=self.hparams.lr,\n",
        "            weight_decay=self.hparams.weight_decay,\n",
        "        )\n",
        "        lr_scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
        "            optimizer, T_max=self.hparams.max_epochs, eta_min=self.hparams.lr / 50\n",
        "        )\n",
        "        return [optimizer], [lr_scheduler]\n",
        "\n",
        "    def compute_the_loss(self, batch, mode=\"train\"):\n",
        "        imgs, _ = batch  # we do not need the labels here\n",
        "        # imgs is a list of length 2, where imgs[0][i] and imgs[1][i] are the positive pairs\n",
        "\n",
        "        # TODO: Calculate the contrastive loss of SimCLR. Try to be as efficient as possible [20 POINTS]\n",
        "\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        return self.info_nce_loss(batch, mode=\"train\")\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        self.info_nce_loss(batch, mode=\"val\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5W1vBj65G5-W"
      },
      "outputs": [],
      "source": [
        "# TODO: re-do experiments in Part 2 and Part 2 using your new Another SSL [5 POINTS]\n",
        "raise NotImplementedError"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WkRs96gG5-W"
      },
      "source": [
        "# References\n",
        "\n",
        "[1] Chen, T., Kornblith, S., Norouzi, M., and Hinton, G. (2020). A simple framework for contrastive learning of visual representations. In International conference on machine learning (pp. 1597-1607). PMLR. ([link](https://arxiv.org/abs/2002.05709))\n",
        "\n",
        "[2] Chen, T., Kornblith, S., Swersky, K., Norouzi, M., and Hinton, G. (2020). Big self-supervised models are strong semi-supervised learners. NeurIPS 2021 ([link](https://arxiv.org/abs/2006.10029)).\n",
        "\n",
        "[3] Oord, A. V. D., Li, Y., and Vinyals, O. (2018). Representation learning with contrastive predictive coding. arXiv preprint arXiv:1807.03748. ([link](https://arxiv.org/abs/1807.03748))\n",
        "\n",
        "[4] Grill, J.B., Strub, F., Altché, F., Tallec, C., Richemond, P.H., Buchatskaya, E., Doersch, C., Pires, B.A., Guo, Z.D., Azar, M.G. and Piot, B. (2020). Bootstrap your own latent: A new approach to self-supervised learning. arXiv preprint arXiv:2006.07733. ([link](https://arxiv.org/abs/2006.07733))\n",
        "\n",
        "[5] Khosla, P., Teterwak, P., Wang, C., Sarna, A., Tian, Y., Isola, P., Maschinot, A., Liu, C. and Krishnan, D. (2020). Supervised contrastive learning. arXiv preprint arXiv:2004.11362. ([link](https://arxiv.org/abs/2004.11362))\n",
        "\n",
        "[6] Zbontar, J., Jing, L., Misra, I., LeCun, Y. and Deny, S. (2021). Barlow twins: Self-supervised learning via redundancy reduction. arXiv preprint arXiv:2103.03230. ([link](https://arxiv.org/abs/2103.03230))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "49342f1adcb34775b4c57bb1934b1d31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_485abf8897bd4c7fb6a1520e6fc310f0",
              "IPY_MODEL_631a8d12428949fbbe4828d20eaec1b4",
              "IPY_MODEL_af9d1ca12c5a49928ad0169ad577de01"
            ],
            "layout": "IPY_MODEL_fe09de4584874289aab4a61b78d4e42a"
          }
        },
        "485abf8897bd4c7fb6a1520e6fc310f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef786ecad5ee463883389ec122bda251",
            "placeholder": "​",
            "style": "IPY_MODEL_82a8ab84e07f4dee9810af09852a8b68",
            "value": "100%"
          }
        },
        "631a8d12428949fbbe4828d20eaec1b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d346421f8344d928342244db3a335e5",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3011955b675e494a8444e5ff1ef30410",
            "value": 1000
          }
        },
        "af9d1ca12c5a49928ad0169ad577de01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e41ce6b526534205a11b6f61b5a0ea3b",
            "placeholder": "​",
            "style": "IPY_MODEL_d211c1765d2e4a2391c76a2409593ff3",
            "value": " 1000/1000 [00:10&lt;00:00, 102.03it/s]"
          }
        },
        "fe09de4584874289aab4a61b78d4e42a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef786ecad5ee463883389ec122bda251": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82a8ab84e07f4dee9810af09852a8b68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6d346421f8344d928342244db3a335e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3011955b675e494a8444e5ff1ef30410": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e41ce6b526534205a11b6f61b5a0ea3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d211c1765d2e4a2391c76a2409593ff3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cd869a3fd4de46cf83ff925b3cf00242": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d2a9b11ae8ab4d22b0d0f826bf85bd51",
              "IPY_MODEL_522becfd6c8245a9b43432006413c0bb",
              "IPY_MODEL_ec8ae4f9e27942169bd95f9f75f7d177"
            ],
            "layout": "IPY_MODEL_ce817f85db9a47dfbb56b32f9a60a2ee"
          }
        },
        "d2a9b11ae8ab4d22b0d0f826bf85bd51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_171839a10544421e8ce4f1e3a72b192d",
            "placeholder": "​",
            "style": "IPY_MODEL_1610c7fc794e4d279b68abd03610e24e",
            "value": "100%"
          }
        },
        "522becfd6c8245a9b43432006413c0bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1eebd013f694f59a6dc9c004a6148be",
            "max": 50,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8b2816d947ba411ba102b930403e143e",
            "value": 50
          }
        },
        "ec8ae4f9e27942169bd95f9f75f7d177": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03cb7e676f4d46e69b52bac345533408",
            "placeholder": "​",
            "style": "IPY_MODEL_52d14b848e29445b98dcca0685179dd8",
            "value": " 50/50 [00:00&lt;00:00, 106.26it/s]"
          }
        },
        "ce817f85db9a47dfbb56b32f9a60a2ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "171839a10544421e8ce4f1e3a72b192d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1610c7fc794e4d279b68abd03610e24e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a1eebd013f694f59a6dc9c004a6148be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b2816d947ba411ba102b930403e143e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "03cb7e676f4d46e69b52bac345533408": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52d14b848e29445b98dcca0685179dd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b969f6ebabe04d1da7a5df245b0afd41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_da8d44d2cb5949ec8c875238ec70445d",
              "IPY_MODEL_237c654bc78549ca854fe96ef75a844e",
              "IPY_MODEL_928f8bfbc9714fe09c1b5eaee5dd1577"
            ],
            "layout": "IPY_MODEL_2b678cc5ff7b4cff9d96cf1078fa08f7"
          }
        },
        "da8d44d2cb5949ec8c875238ec70445d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e16afdd57341497fb96fc21d2d4aa4cd",
            "placeholder": "​",
            "style": "IPY_MODEL_38409d162dc1497c89a11b8b8c9c38d4",
            "value": "Sanity Checking DataLoader 0: 100%"
          }
        },
        "237c654bc78549ca854fe96ef75a844e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02d7115a012d4de78bfa32118e7a8ed8",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d809c0b57074454b9bcb20662f6bf8de",
            "value": 2
          }
        },
        "928f8bfbc9714fe09c1b5eaee5dd1577": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1b5410b1fea4c6b889f70782b56fba2",
            "placeholder": "​",
            "style": "IPY_MODEL_135d6f1c4531467ea52ad0bbb02e09ab",
            "value": " 2/2 [00:00&lt;00:00, 13.97it/s]"
          }
        },
        "2b678cc5ff7b4cff9d96cf1078fa08f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "e16afdd57341497fb96fc21d2d4aa4cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38409d162dc1497c89a11b8b8c9c38d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "02d7115a012d4de78bfa32118e7a8ed8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d809c0b57074454b9bcb20662f6bf8de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a1b5410b1fea4c6b889f70782b56fba2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "135d6f1c4531467ea52ad0bbb02e09ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c2b8ca9b0a8340daa70f10b0a5721106": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f69d28c07bd54db49ef0a3e167b6c410",
              "IPY_MODEL_bdbd339ae5fe41139e4fc0db10d8d298",
              "IPY_MODEL_1c069fc5295f43e0bfa22881aa233f05"
            ],
            "layout": "IPY_MODEL_5f4f662acc3144f39ab11d5e266960ca"
          }
        },
        "f69d28c07bd54db49ef0a3e167b6c410": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a887f045d2504205991ce6dde8c23e2b",
            "placeholder": "​",
            "style": "IPY_MODEL_0cf091503fa04b16b28216e3bda7b26d",
            "value": "Epoch 1:  77%"
          }
        },
        "bdbd339ae5fe41139e4fc0db10d8d298": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8c011993d3b43dca560864d4444e18e",
            "max": 390,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_515f5948130a458c8c2e01a75733b95f",
            "value": 300
          }
        },
        "1c069fc5295f43e0bfa22881aa233f05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2277882dc8d0454b8e3fbcde196cdfcd",
            "placeholder": "​",
            "style": "IPY_MODEL_7088a5234c5745b6ad2f53127a89b861",
            "value": " 300/390 [03:59&lt;01:11,  1.25it/s, v_num=2]"
          }
        },
        "5f4f662acc3144f39ab11d5e266960ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "a887f045d2504205991ce6dde8c23e2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0cf091503fa04b16b28216e3bda7b26d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c8c011993d3b43dca560864d4444e18e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "515f5948130a458c8c2e01a75733b95f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2277882dc8d0454b8e3fbcde196cdfcd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7088a5234c5745b6ad2f53127a89b861": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3bb408e506ab48ae92de8e4b154788a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e0b9b5ee84644289a5ce531f5d267c67",
              "IPY_MODEL_3c84a130ec2048e0b70c234c27ab4543",
              "IPY_MODEL_18a830bfb0ae4397b74ce1a93a2edf5a"
            ],
            "layout": "IPY_MODEL_adcb81064a1342168712555ecac8fdc5"
          }
        },
        "e0b9b5ee84644289a5ce531f5d267c67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba1db6d80cb1407fa892f99b256a37e0",
            "placeholder": "​",
            "style": "IPY_MODEL_73a175fdb1334f048d4495c1cf66c10b",
            "value": "100%"
          }
        },
        "3c84a130ec2048e0b70c234c27ab4543": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1fabd1996ba348e5a6f236c9d86bacdd",
            "max": 50,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aa79f19011c247fca3abbcda27c68877",
            "value": 50
          }
        },
        "18a830bfb0ae4397b74ce1a93a2edf5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_040b7ad81034402ea57b0656e63b9e05",
            "placeholder": "​",
            "style": "IPY_MODEL_546a08d7c2644457b41714cc99bb5e34",
            "value": " 50/50 [00:00&lt;00:00, 113.69it/s]"
          }
        },
        "adcb81064a1342168712555ecac8fdc5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba1db6d80cb1407fa892f99b256a37e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73a175fdb1334f048d4495c1cf66c10b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1fabd1996ba348e5a6f236c9d86bacdd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa79f19011c247fca3abbcda27c68877": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "040b7ad81034402ea57b0656e63b9e05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "546a08d7c2644457b41714cc99bb5e34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3a83d312b0304ca28a56bb4aa6a5eb3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4199ef86cf374429a1938384d5925c92",
              "IPY_MODEL_e414eb5c487a42aea93c927ab1920202",
              "IPY_MODEL_378476a1756a48c2a93b7b2fc38eed78"
            ],
            "layout": "IPY_MODEL_0c454c8f17c84df08eab670b77e02b5e"
          }
        },
        "4199ef86cf374429a1938384d5925c92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7dae7f51d52b4621b525cf5d32aca92e",
            "placeholder": "​",
            "style": "IPY_MODEL_1c9a78e9c5824255a3a4ca7336a0a5c0",
            "value": "100%"
          }
        },
        "e414eb5c487a42aea93c927ab1920202": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_edd3552cc97348c5993d09d41117d57c",
            "max": 80,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_034465d7bcf248d3847c2a50a336492d",
            "value": 80
          }
        },
        "378476a1756a48c2a93b7b2fc38eed78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b00e5dc8945f49459e18ab9131925284",
            "placeholder": "​",
            "style": "IPY_MODEL_0759bc89c3464071817bbe3fd1698096",
            "value": " 80/80 [00:00&lt;00:00, 116.40it/s]"
          }
        },
        "0c454c8f17c84df08eab670b77e02b5e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7dae7f51d52b4621b525cf5d32aca92e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c9a78e9c5824255a3a4ca7336a0a5c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "edd3552cc97348c5993d09d41117d57c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "034465d7bcf248d3847c2a50a336492d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b00e5dc8945f49459e18ab9131925284": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0759bc89c3464071817bbe3fd1698096": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}